{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2.3 요약\n",
    "# 데이터 가져오기\n",
    "import os\n",
    "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
    "\n",
    "import pandas as pd\n",
    "def load_housing_data(housing_path=HOUSING_PATH):\n",
    "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "housing = load_housing_data()\n",
    "\n",
    "\n",
    "# 중요 특성인 중간소득을 계층 별로 나눠 계층적 샘플링\n",
    "import numpy as np\n",
    "housing[\"income_cat\"] = pd.cut(housing[\"median_income\"],\n",
    "                               bins=[0., 1.5, 3.0, 4.5, 6., np.inf],\n",
    "                               labels=[1, 2, 3, 4, 5])\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(housing, housing[\"income_cat\"]):\n",
    "    strat_train_set = housing.loc[train_index]\n",
    "    strat_test_set = housing.loc[test_index]\n",
    "\n",
    "    \n",
    "# 계층적 샘플링에 사용했던 income_cat 특성 제거하기\n",
    "for set_ in (strat_train_set, strat_test_set):\n",
    "    set_.drop(\"income_cat\", axis=1, inplace=True)\n",
    "\n",
    "## 2.4는 데이터 탐색과 시각화일 뿐, 2.5에 영향을 주진 않는다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2.5 머신러닝 알고리즘을 위한 데이터 준비\n",
    "'''\n",
    "함수로 자동화\n",
    "원래 훈련 세트로 복원하고, 예측 변수과 타깃값(레이블)을 분리한다.\n",
    "drop()은 복사본을 만들며, 기존에 영향을 주지 않는다.\n",
    "'''\n",
    "\n",
    "housing = strat_train_set.drop(\"median_house_value\", axis=1)\n",
    "housing_labels = strat_train_set[\"median_house_value\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.5.1 데이터 정제\n",
    "'''\n",
    "누락된 특성을 처리하자\n",
    "1. 해당 구역 제거\n",
    "2. 전체 특성 삭제\n",
    "3. 어떤 값으로 채우기 -> 계산한 중간값을 저장하고 사용.\n",
    "'''\n",
    "\n",
    "#housing.dropna(subset=[\"total_bedrooms\"])\n",
    "#housing.drop(\"total_bedrooms\", axis=1)\n",
    "#median = housing[\"total_bedrooms\"].median()\n",
    "#housing[\"total_bedrooms\"].fillna(median, inplace=True)\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "사이킷런의 SimpleImputer -> 누락된 값을 손쉽게 다루게 해줌\n",
    "일단, 특성의 중간값으로 대체하게 해보자\n",
    "'''\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "중간값은 수치형 데이터에서만 계산될 수 있음 -> 텍스트 특성인 ocean_proximity를 제외한 데이터 복사본 생성\n",
    "'''\n",
    "\n",
    "housing_num = housing.drop(\"ocean_proximity\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleImputer(strategy='median')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "imputer 객체의 fit() 메서드 사용해서 훈련 데이터에 적용\n",
    "'''\n",
    "\n",
    "imputer.fit(housing_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-118.51  ,   34.26  ,   29.    , 2119.5   ,  433.    , 1164.    ,\n",
       "        408.    ,    3.5409])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "imputer는 각 특성의 중간값을 계산해서 그 결과를 객체의 statistics_ 속성에 저장한다\n",
    "나중에 어떤 값이 누락될 지 모르니 모든 수치형 특성에 imputer를 적용하자\n",
    "'''\n",
    "\n",
    "imputer.statistics_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-118.51  ,   34.26  ,   29.    , 2119.5   ,  433.    , 1164.    ,\n",
       "        408.    ,    3.5409])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_num.median().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-121.89  ,   37.29  ,   38.    , ...,  710.    ,  339.    ,\n",
       "           2.7042],\n",
       "       [-121.93  ,   37.05  ,   14.    , ...,  306.    ,  113.    ,\n",
       "           6.4214],\n",
       "       [-117.2   ,   32.77  ,   31.    , ...,  936.    ,  462.    ,\n",
       "           2.8621],\n",
       "       ...,\n",
       "       [-116.4   ,   34.09  ,    9.    , ..., 2098.    ,  765.    ,\n",
       "           3.2723],\n",
       "       [-118.01  ,   33.82  ,   31.    , ..., 1356.    ,  356.    ,\n",
       "           4.0625],\n",
       "       [-122.45  ,   37.77  ,   52.    , ..., 1269.    ,  639.    ,\n",
       "           3.575 ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "이제 학습된 imputer 객체를 사용해 훈련 세트에 누락된 값을 중간값으로 바꿀 수 있다\n",
    "'''\n",
    "\n",
    "X = imputer.transform(housing_num)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "이 결과는 평범한 넘파이 배열이다. 다시 판다스 데이터프레임으로 되돌리자\n",
    "'''\n",
    "\n",
    "housing_tr = pd.DataFrame(X, columns=housing_num.columns, index=housing_num.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17606</th>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18632</th>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14650</th>\n",
       "      <td>NEAR OCEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3230</th>\n",
       "      <td>INLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3555</th>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19480</th>\n",
       "      <td>INLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8879</th>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13685</th>\n",
       "      <td>INLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4937</th>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4861</th>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ocean_proximity\n",
       "17606       <1H OCEAN\n",
       "18632       <1H OCEAN\n",
       "14650      NEAR OCEAN\n",
       "3230           INLAND\n",
       "3555        <1H OCEAN\n",
       "19480          INLAND\n",
       "8879        <1H OCEAN\n",
       "13685          INLAND\n",
       "4937        <1H OCEAN\n",
       "4861        <1H OCEAN"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.5.2 텍스트와 번주형 특성 다루기\n",
    "# OrdinalEncoder, OneHotEncoder\n",
    "'''\n",
    "이 데이터셋에는 텍스트 특성이 ocean_proximity 하나다\n",
    "'''\n",
    "\n",
    "housing_cat = housing[[\"ocean_proximity\"]]\n",
    "housing_cat.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [4.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "가능한 값을 제한된 개수로 나열한 것. 각 값은 카테고리를 나타낸다\n",
    "이 특성은 범주형 특성이다.\n",
    "이를 숫자로 변환하겠다\n",
    "OrdinalEncode 클래스를 사용하자\n",
    "'''\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "housing_cat_encoded = ordinal_encoder.fit_transform(housing_cat)\n",
    "housing_cat_encoded[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['<1H OCEAN', 'INLAND', 'ISLAND', 'NEAR BAY', 'NEAR OCEAN'],\n",
       "       dtype=object)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "categories_ 인스턴스 변수 -> 카테고리 목록을 얻을 수 있음\n",
    "각 범주형 특성마다 카테고리들의 1D 배열을 담은 리스트가 반환 (이 경우에는 범주형 특성이 하나뿐)\n",
    "'''\n",
    "\n",
    "ordinal_encoder.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<16512x5 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 16512 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "이 표현방식의 문제 : 가까이 있는 두 값이 떨어져 있는 두 값보다 더 비슷하다고 생각한다.\n",
    "이 문제는 일반적으로 카테고리별 이진 특성을 만들어 해결한다.\n",
    "한 특성이 1, 나머지 특성은 0 -> 원-핫 인코딩\n",
    "'''\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "cat_encoder = OneHotEncoder()\n",
    "housing_cat_1hot = cat_encoder.fit_transform(housing_cat)\n",
    "housing_cat_1hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "사이파이 희소행렬 (0이 아닌 원소의 위치만 저장함)\n",
    "넘파이 배열로 바꾸려면 toarray() 함수\n",
    "'''\n",
    "\n",
    "housing_cat_1hot.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['<1H OCEAN', 'INLAND', 'ISLAND', 'NEAR BAY', 'NEAR OCEAN'],\n",
       "       dtype=object)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_encoder.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.5.3 나만의 변환기\n",
    "\n",
    "'''\n",
    "사이킷런이 유용한 변환기를 많이 제공하지만 자신만의 변환기를 만들어야 할 때가 있다.\n",
    "사이킷런은 (상속이 아닌) 덕 타이핑을 지원하므로 fit(), transform(), fit_gransform() 메서드를 구현한 파이썬 클래스를 만들면 된다.\n",
    "\n",
    "마지막 메서드는 TransformerMixin을 상속하면 자동으로 생성된다.\n",
    "또한 BaseExtimator를 상속하면 하이퍼파라미터 튜닝에 필요한 두 메서드(get_params()와 set_params())를 추가로 얻게 된다.\n",
    "\n",
    "앞서 이야기한 조합 특성을 추가하는 간단한 변환기를 보여주겠다.\n",
    "'''\n",
    "\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "rooms_ix, bedrooms_ix, population_ix, households_ix = 3, 4, 5, 6\n",
    "\n",
    "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, add_bedrooms_per_room = True):\n",
    "        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        rooms_per_household = X[:, rooms_ix] / X[:, households_ix]\n",
    "        population_per_household = X[:, population_ix] / X[:, households_ix]\n",
    "        if self.add_bedrooms_per_room:\n",
    "            bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n",
    "            return np.c_[X, rooms_per_household, population_per_household, bedrooms_per_room]\n",
    "        \n",
    "        else:\n",
    "            return np.c_[X, rooms_per_household, population_per_household]\n",
    "\n",
    "attr_adder = CombinedAttributesAdder(add_bedrooms_per_room=False)\n",
    "housing_extra_attribs = attr_adder.transform(housing.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.5.4 특성 스케일링\n",
    "'''\n",
    "표준화, 정규화 등\n",
    "사이킷런 - StandardScaler\n",
    "'''\n",
    "\n",
    "# 2.5.5 변환 파이프라인\n",
    "'''\n",
    "변환 단계가 많은데, 정확한 순서대로 실행되어야 한다.\n",
    "사이킷런에는 변환을 순서대로 처리해주는 Pipeline 클래스가 있다.\n",
    "수치형 특성을 처리하는 간단한 파이프라인을 보자.\n",
    "'''\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "    ('attribs_adder', CombinedAttributesAdder()),\n",
    "    ('std_scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "housing_num_tr = num_pipeline.fit_transform(housing_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "(이름, 추정기) 쌍의 목록을 입력으로 받는다.\n",
    "마지막 단계 - 변환기, 추정기 모두 사용 가능. 그 외에는 변환기여야 한다. (즉, fit_transform() 함수를 가지고 있어야 한다.)\n",
    "\n",
    "하나의 변환기로 각 열마다 적절한 변환을 적용하여 모든 열을 처리할 수 있다면 더 편리할 것이다??\n",
    "ColumnTransformer\n",
    "'''\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "num_attribs = list(housing_num)\n",
    "cat_attribs = [\"ocean_proximity\"]\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "    (\"nun\", num_pipeline, num_attribs),\n",
    "    (\"cat\", OneHotEncoder(), cat_attribs),\n",
    "])\n",
    "\n",
    "housing_prepared = full_pipeline.fit_transform(housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "ColumnTransformer 클래스를 임포트\n",
    "수치형 열 이름의 리스트\n",
    "범주형 열 이름의 리스트 만들기\n",
    "ColumnTransformer 객체 만들기 (튜플을 리스트로 받음 - 이름,변환기,변환기)\n",
    "ColumnTransformer를 주택 데이터에 적용\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.6 모델 선택과 훈련\n",
    "\n",
    "'''\n",
    "이제 모델을 선택하고 훈련시킬 준비가 되었다.\n",
    "\n",
    "2.6.1 훈련 세트에서 훈련하고 평가하기\n",
    "선형회귀 모델을 훈련시켜보겠다\n",
    "'''\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측: [210644.60459286 317768.80697211 210956.43331178  59218.98886849\n",
      " 189747.55849879]\n",
      "레이블: [286600.0, 340600.0, 196900.0, 46300.0, 254500.0]\n"
     ]
    }
   ],
   "source": [
    "some_data = housing.iloc[:5]\n",
    "some_labels = housing_labels.iloc[:5]\n",
    "some_data_prepared = full_pipeline.transform(some_data)\n",
    "\n",
    "print(\"예측:\", lin_reg.predict(some_data_prepared))\n",
    "\n",
    "print(\"레이블:\", list(some_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68628.19819848923"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "housing_predictions = lin_reg.predict(housing_prepared)\n",
    "lin_mse = mean_squared_error(housing_labels, housing_predictions)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "lin_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor()"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "과소적합\n",
    "더 복잡한 모델을 시도해보자\n",
    "'''\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg = DecisionTreeRegressor()\n",
    "tree_reg.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_predictions = tree_reg.predict(housing_prepared)\n",
    "tree_mse = mean_squared_error(housing_labels, housing_predictions)\n",
    "tree_rmse = np.sqrt(tree_mse)\n",
    "tree_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "과대적합\n",
    "\n",
    "2.6.2 교차검증을 사용한 평가\n",
    "결정 트리 모델을 평가하는 방법?\n",
    "train_test_split -> 더 작은 훈련세트와 검증세트로 나누기 / 사이킷런의 k-겹 교차검증\n",
    "'''\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(tree_reg, housing_prepared, housing_labels,\n",
    "                        scoring=\"neg_mean_squared_error\", cv=10)\n",
    "tree_rmse_scores = np.sqrt(-scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "점수: [68928.85727801 67594.65807956 69866.45250403 69303.89436209\n",
      " 72683.43056727 74701.49965157 70965.16049043 70579.05333567\n",
      " 77163.6491091  70225.81859874]\n",
      "평균: 71201.24739764762\n",
      "표준편차: 2737.627806937331\n"
     ]
    }
   ],
   "source": [
    "def display_scores(scores):\n",
    "    print(\"점수:\", scores)\n",
    "    print(\"평균:\", scores.mean())\n",
    "    print(\"표준편차:\", scores.std())\n",
    "\n",
    "display_scores(tree_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "점수: [66763.70922083 66962.56645975 70347.95244419 74746.92830953\n",
      " 68031.13388938 71215.74436195 64966.62626808 68277.96814759\n",
      " 71552.91566558 67662.53153935]\n",
      "평균: 69052.80763062098\n",
      "표준편차: 2737.0104998331326\n"
     ]
    }
   ],
   "source": [
    "lin_scores = cross_val_score(lin_reg, housing_prepared, housing_labels,\n",
    "                            scoring=\"neg_mean_squared_error\", cv=10)\n",
    "\n",
    "lin_rmse_scores = np.sqrt(-lin_scores)\n",
    "display_scores(lin_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'forest_rmse' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-956e5a6ad689>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mforest_reg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhousing_prepared\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhousing_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mforest_rmse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'forest_rmse' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "forest_reg = RandomForestRegressor()\n",
    "forest_reg.fit(housing_prepared, housing_labels)\n",
    "\n",
    "forest_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'forest_rmse_scores' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-9fb5df41162d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdisplay_scores\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mforest_rmse_scores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'forest_rmse_scores' is not defined"
     ]
    }
   ],
   "source": [
    "display_scores(forest_rmse_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
